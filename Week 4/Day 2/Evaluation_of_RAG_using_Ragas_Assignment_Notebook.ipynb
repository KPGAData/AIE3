{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa8ykQk92aLX"
      },
      "source": [
        "# Evaluation of RAG Using Ragas\n",
        "\n",
        "In the following notebook we'll explore how to evaluate RAG pipelines using a powerful open-source tool called \"Ragas\". This will give us tools to evaluate component-wise metrics, as well as end-to-end metrics about the performance of our RAG pipelines.\n",
        "\n",
        "In the following notebook we'll complete the following tasks:\n",
        "\n",
        "- ü§ù Breakout Room Part #1:\n",
        "  1. Install required libraries\n",
        "  2. Set Environment Variables\n",
        "  3. Creating a simple RAG pipeline with [LangChain v0.2.0](https://python.langchain.com/v0.2/docs/versions/v0_2/)\n",
        "  4. Synthetic Dataset Generation for Evaluation using the [Ragas](https://github.com/explodinggradients/ragas) framework.\n",
        "  \n",
        "\n",
        "- ü§ù Breakout Room Part #2:\n",
        "  1. Evaluating our pipeline with Ragas\n",
        "  3. Making Adjustments to our RAG Pipeline\n",
        "  4. Evaluating our Adjusted pipeline against our baseline\n",
        "  5. Testing OpenAI's Claim\n",
        "\n",
        "The only way to get started is to get started - so let's grab our dependencies for the day!\n",
        "\n",
        "> NOTE: Using this notebook as presented will occur a charge of ~$3USD from OpenAI usage. Most of this cost is produced by the Synthetic Data Generation step - if you want to reduce costs, please use the provided commented code to leverage `GPT-3.5-Turbo` as the `critic_llm`!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8h4yh6f7q9uN"
      },
      "source": [
        "## Motivation\n",
        "\n",
        "A claim, made by OpenAI, is that their `text-embedding-3-small` is better (generally) than their `text-embedding-ada-002` model.\n",
        "\n",
        "Here's some passages from their [blog](https://openai.com/blog/new-embedding-models-and-api-updates) about the `text-embedding-3` release:\n",
        "\n",
        "> `text-embedding-3-small` is our new highly efficient embedding model and provides a significant upgrade over its predecessor, the `text-embedding-ada-002` model...\n",
        "\n",
        "> **Stronger performance.** Comparing `text-embedding-ada-002` to `text-embedding-3-small`, the average score on a commonly used benchmark for multi-language retrieval ([MIRACL](https://github.com/project-miracl/miracl)) has increased from 31.4% to 44.0%, while the average score on a commonly used benchmark for English tasks ([MTEB](https://github.com/embeddings-benchmark/mteb)) has increased from 61.0% to 62.3%.\n",
        "\n",
        "Well, with a library like Ragas - we can put that claim to the test!\n",
        "\n",
        "If what they claim is true - we should see an increase on related metrics by using the new embedding model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAH1znJ2pIp3"
      },
      "source": [
        "# ü§ù Breakout Room Part #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpkXAmMZpLhm"
      },
      "source": [
        "## Task 1: Installing Required Libraries\n",
        "\n",
        "A reminder that one of the [key features](https://blog.langchain.dev/langchain-v0-1-0/) of LangChain v0.1.0 is the compartmentalization of the various LangChain ecosystem packages!\n",
        "\n",
        "So let's begin grabbing all of our LangChain related packages!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BN13TZlSCv4",
        "outputId": "51d9c154-af83-42b2-ce72-9656729ecb9d"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q langchain langchain-openai langchain_core langchain-community langchainhub openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fm7gXsD6pqG0"
      },
      "source": [
        "We'll also get the \"star of the show\" today, which is Ragas!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvAvDNWBpjQ1",
        "outputId": "20ff8c89-11db-4071-b0a0-6b9bfc0e215f"
      },
      "outputs": [],
      "source": [
        "!pip install -qU ragas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9q6Z9oTpw3X"
      },
      "source": [
        "We'll be leveraging [QDrant](https://qdrant.tech/) again as our LangChain `VectorStore`.\n",
        "\n",
        "We'll also install `pymupdf` and its dependencies which will allow us to load PDFs using the `PyMuPDFLoader` in the `langchain-community` package!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAJK95napn8I",
        "outputId": "58f04109-385b-44c7-d3cb-4547d8acaea1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "wandb 0.16.6 requires protobuf!=4.21.0,<5,>=3.19.0; sys_platform != \"linux\", but you have protobuf 5.27.2 which is incompatible.\n",
            "opentelemetry-proto 1.25.0 requires protobuf<5.0,>=3.19, but you have protobuf 5.27.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -qU qdrant-client pymupdf pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_C2JvG1qO3h"
      },
      "source": [
        "## Task 2: Set Environment Variables\n",
        "\n",
        "Let's set up our OpenAI API key so we can leverage their API later on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Lhqp5rUThG-",
        "outputId": "97cb739d-66b4-4476-ca04-b6257004178f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "from getpass import getpass\n",
        "\n",
        "openai.api_key = getpass(\"Please provide your OpenAI Key: \")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai.api_key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFbWNvo3rZ4H"
      },
      "source": [
        "## Task 3: Creating a Simple RAG Pipeline with LangChain v0.1.0\n",
        "\n",
        "Building on what we learned last week, we'll be leveraging LangChain v0.1.0 and LCEL to build a simple RAG pipeline that we can baseline with Ragas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV_BOewX8CW0"
      },
      "source": [
        "## Building our RAG pipeline\n",
        "\n",
        "Let's review the basic steps of RAG again:\n",
        "\n",
        "- Create an Index\n",
        "- Use retrieval to obtain pieces of context from our Index that are similar to our query\n",
        "- Use a LLM to generate responses based on the retrieved context\n",
        "\n",
        "Let's get started by creating our index.\n",
        "\n",
        "> NOTE: We're going to start leaning on the term \"index\" to refer to our `VectorStore`, `VectorDatabase`, etc. We can think of \"index\" as the catch-all term, whereas `VectorStore` and the like relate to the specific technologies used to create, store, and interact with the index."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VDGJdxCJEVc"
      },
      "source": [
        "### Creating an Index\n",
        "\n",
        "You'll notice that the largest changes (outside of some import changes) are that our old favourite chains are back to being bundled in an easily usable abstraction.\n",
        "\n",
        "We can still create custom chains using LCEL - but we can also be more confident that our pre-packaged chains are creating using LCEL under the hood."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmFFThawK8lO"
      },
      "source": [
        "#### Loading Data\n",
        "\n",
        "Let's start by loading some data!\n",
        "\n",
        "> NOTE: You'll notice that we're using a document loader from the community package of LangChain. This is part of the v0.2.0 changes that make the base (`langchain-core`) package remain lightweight while still providing access to some of the more powerful community integrations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DTDNFXaBSO2j"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "\n",
        "loader = PyMuPDFLoader(\n",
        "    \"https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf\",\n",
        ")\n",
        "\n",
        "documents = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3dJYlBCIX_p",
        "outputId": "1383c5b7-bb72-49ea-d323-fcd9eed48d60"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'source': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf',\n",
              " 'file_path': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf',\n",
              " 'page': 0,\n",
              " 'total_pages': 195,\n",
              " 'format': 'PDF 1.3',\n",
              " 'title': 'The Pmarca Blog Archives',\n",
              " 'author': '',\n",
              " 'subject': '',\n",
              " 'keywords': '',\n",
              " 'creator': '',\n",
              " 'producer': 'Mac OS X 10.10 Quartz PDFContext',\n",
              " 'creationDate': \"D:20150110020418Z00'00'\",\n",
              " 'modDate': \"D:20150110020418Z00'00'\",\n",
              " 'trapped': ''}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents[0].metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQUl3sbZK4_1"
      },
      "source": [
        "#### Transforming Data\n",
        "\n",
        "Now that we've got our single document - let's split it into smaller pieces so we can more effectively leverage it with our retrieval chain!\n",
        "\n",
        "We'll start with the classic: `RecursiveCharacterTextSplitter`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6Nt2E1xnLNgr"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 200,\n",
        "    chunk_overlap = 50\n",
        ")\n",
        "\n",
        "documents = text_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilzwQxhiLcVV"
      },
      "source": [
        "Let's confirm we've split our document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wRw6a4aLfWh",
        "outputId": "a707bbf6-6338-45fc-a75e-86d693dfe2c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1864"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZ93HkYcMJwW"
      },
      "source": [
        "#### Loading OpenAI Embeddings Model\n",
        "\n",
        "We'll need a process by which we can convert our text into vectors that allow us to compare to our query vector.\n",
        "\n",
        "Let's use OpenAI's `text-embedding-ada-002` for this task!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JU6CrDVZMgKe"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(\n",
        "    model=\"text-embedding-ada-002\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVtZR9JPLtR4"
      },
      "source": [
        "#### Creating a QDrant VectorStore\n",
        "\n",
        "Now that we have documents - we'll need a place to store them alongside their embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "978TWiCtMA0B"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import Qdrant\n",
        "\n",
        "qdrant_vector_store = Qdrant.from_documents(\n",
        "    documents,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"PMarca Blogs\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk50NmrMDlWu"
      },
      "source": [
        "####‚ùì Question #1:\n",
        "\n",
        "List out a few of the techniques that Qdrant uses that make it performant.\n",
        "\n",
        "> **Answer:**\n",
        ">> Qdrant uses several techniques to make it performant\n",
        ">> - Qdrant is written in Rust programming language, which makes it performant and reliable\n",
        ">> - Qdrant uses Hierarchical navigable Small World (HNSW) indexing for fast retrieval\n",
        ">> - Qdrant offers several implementations like memory, on-disk, on-cloud to provide best performance and cost optimization options\n",
        ">> - Qdrant automatically enables indexes and memmap storage when a certain number of records is reached, optimizing performance as the database size grows\n",
        ">> - Qdrant employs Vaccuum Optimizer, which combines multiple small segments into larger ones to optimize search performance\n",
        ">> - Qdrant uses quantization for more efficient storage and faster retrieval \n",
        "\n",
        "> NOTE: Check the [documentation](https://qdrant.tech/documentation/overview/) for more information about QDrant!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ht6bJX9PAY"
      },
      "source": [
        "#### Creating a Retriever\n",
        "\n",
        "To complete our index, all that's left to do is expose our vectorstore as a retriever - which we can do the same way we would in previous version of LangChain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xne8P5dQTUiR"
      },
      "outputs": [],
      "source": [
        "retriever = qdrant_vector_store.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO_DFBVKNvNm"
      },
      "source": [
        "#### Testing our Retriever\n",
        "\n",
        "Now that we've gone through the trouble of creating our retriever - let's see it in action!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "I9_ONxpnN0n6"
      },
      "outputs": [],
      "source": [
        "retrieved_documents = retriever.invoke(\"What is a rule of thumb for selecting an industry to invest in?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Za12yt4OBy1",
        "outputId": "6dfa1ae5-8198-49a1-b213-96b34a1a5147"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='the existing order ‚Äî and make sure that those forces of change\\nhave a reasonable chance at succeeding.\\nSecond rule of thumb:\\nOnce you have picked an industry, get right to the center of it' metadata={'source': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'file_path': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'page': 125, 'total_pages': 195, 'format': 'PDF 1.3', 'title': 'The Pmarca Blog Archives', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Mac OS X 10.10 Quartz PDFContext', 'creationDate': \"D:20150110020418Z00'00'\", 'modDate': \"D:20150110020418Z00'00'\", 'trapped': '', '_id': '036019aea40b49efa31034a9e04ec300', '_collection_name': 'PMarca Blogs'}\n",
            "page_content='Third rule:\\nIn a rapidly changing Held like technology, the best place to\\nget experience when you‚Äôre starting out is in younger, high-\\ngrowth companies.' metadata={'source': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'file_path': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'page': 127, 'total_pages': 195, 'format': 'PDF 1.3', 'title': 'The Pmarca Blog Archives', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Mac OS X 10.10 Quartz PDFContext', 'creationDate': \"D:20150110020418Z00'00'\", 'modDate': \"D:20150110020418Z00'00'\", 'trapped': '', '_id': 'ea84cb607bca4c6bb1b6a21b9ecf64ef', '_collection_name': 'PMarca Blogs'}\n",
            "page_content='where the great opportunities can be found.\\nApply this rule when selecting which company to go to. Go to\\nthe company where all the action is happening.' metadata={'source': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'file_path': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'page': 125, 'total_pages': 195, 'format': 'PDF 1.3', 'title': 'The Pmarca Blog Archives', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Mac OS X 10.10 Quartz PDFContext', 'creationDate': \"D:20150110020418Z00'00'\", 'modDate': \"D:20150110020418Z00'00'\", 'trapped': '', '_id': 'a5a65b8c0dc4485cade60e879c22bdb4', '_collection_name': 'PMarca Blogs'}\n",
            "page_content='growth companies.\\n(This is not necessarily true in older and more established\\nindustries, but those aren‚Äôt the industries we‚Äôre talking about.)' metadata={'source': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'file_path': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'page': 127, 'total_pages': 195, 'format': 'PDF 1.3', 'title': 'The Pmarca Blog Archives', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Mac OS X 10.10 Quartz PDFContext', 'creationDate': \"D:20150110020418Z00'00'\", 'modDate': \"D:20150110020418Z00'00'\", 'trapped': '', '_id': '67bd7ff55204470db3b5c6447ca85268', '_collection_name': 'PMarca Blogs'}\n"
          ]
        }
      ],
      "source": [
        "for doc in retrieved_documents:\n",
        "  print(doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8MKsT6JTgCU"
      },
      "source": [
        "### Creating a RAG Chain\n",
        "\n",
        "Now that we have the \"R\" in RAG taken care of - let's look at creating the \"AG\"!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zs7qBLaEQEic"
      },
      "source": [
        "#### Creating a Prompt Template\n",
        "\n",
        "There are a few different ways we could create our prompt template - we could create a custom template, as seen in the code below, or we could simply pull a prompt from the prompt hub! Let's look at an example of that!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "eRCq_OKUQbKk"
      },
      "outputs": [],
      "source": [
        "from langchain import hub\n",
        "\n",
        "retrieval_qa_prompt = hub.pull(\"langchain-ai/retrieval-qa-chat\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FziTftV5Q1H-",
        "outputId": "21189f0e-4b5d-4146-8071-eb0fff4a6f13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer any use questions based solely on the context below:\n",
            "\n",
            "<context>\n",
            "{context}\n",
            "</context>\n"
          ]
        }
      ],
      "source": [
        "print(retrieval_qa_prompt.messages[0].prompt.template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyq88IPFRGoT"
      },
      "source": [
        "As you can see - the prompt template is simple (and has a small error) - so we'll create our own to be a bit more specific!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ijSNkTAjTsep"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "template = \"\"\"Answer the question based only on the following context. If you cannot answer the question with the context, please respond with 'I don't know':\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYHnPaXl-cvJ"
      },
      "source": [
        "#### Setting Up our Basic QA Chain\n",
        "\n",
        "Now we can instantiate our basic RAG chain!\n",
        "\n",
        "We'll use LCEL directly just to see an example of it - but you could just as easily use an abstraction here to achieve the same goal!\n",
        "\n",
        "We'll also ensure to pass-through our context - which is critical for RAGAS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-TsjUWjbUfbW"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "primary_qa_llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "retrieval_augmented_qa_chain = (\n",
        "    # INVOKE CHAIN WITH: {\"question\" : \"<<SOME USER QUESTION>>\"}\n",
        "    # \"question\" : populated by getting the value of the \"question\" key\n",
        "    # \"context\"  : populated by getting the value of the \"question\" key and chaining it into the base_retriever\n",
        "    {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
        "    # \"context\"  : is assigned to a RunnablePassthrough object (will not be called or considered in the next step)\n",
        "    #              by getting the value of the \"context\" key from the previous step\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    # \"response\" : the \"context\" and \"question\" values are used to format our prompt object and then piped\n",
        "    #              into the LLM and stored in a key called \"response\"\n",
        "    # \"context\"  : populated by getting the value of the \"context\" key from the previous step\n",
        "    | {\"response\": prompt | primary_qa_llm, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MgAa9JwBuJx"
      },
      "source": [
        "####üèóÔ∏è Activity #1:\n",
        "\n",
        "Describe the pipeline shown above in simple terms. You can include a diagram if desired.\n",
        "\n",
        "> **Answer:** The LCEL chain above is a series of steps piped from left and right, where each step takes input from the previous step and sends output to the next step. It starts with capturing user `question` and sending it to `retriever` which sets the `context`. The `context` is passed through to the LLM along with the `question` to the `ChatPrompt` which provides the `response`. The final output is the `response, context` tuple. The same is represented below as ASCII art. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -qU grandalf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                       +---------------------------------+                         \n",
            "                       | Parallel<context,question>Input |                         \n",
            "                       +---------------------------------+                         \n",
            "                           *****                   ****                            \n",
            "                        ***                            ****                        \n",
            "                     ***                                   ****                    \n",
            "+--------------------------------+                             **                  \n",
            "| Lambda(itemgetter('question')) |                              *                  \n",
            "+--------------------------------+                              *                  \n",
            "                 *                                              *                  \n",
            "                 *                                              *                  \n",
            "                 *                                              *                  \n",
            "     +----------------------+                   +--------------------------------+ \n",
            "     | VectorStoreRetriever |                   | Lambda(itemgetter('question')) | \n",
            "     +----------------------+                   +--------------------------------+ \n",
            "                           *****                   *****                           \n",
            "                                ***             ***                                \n",
            "                                   ***       ***                                   \n",
            "                       +----------------------------------+                        \n",
            "                       | Parallel<context,question>Output |                        \n",
            "                       +----------------------------------+                        \n",
            "                                         *                                         \n",
            "                                         *                                         \n",
            "                                         *                                         \n",
            "                            +------------------------+                             \n",
            "                            | Parallel<context>Input |                             \n",
            "                            +------------------------+                             \n",
            "                              ****               ****                              \n",
            "                           ***                       ***                           \n",
            "                         **                             **                         \n",
            "     +-------------------------------+              +-------------+                \n",
            "     | Lambda(itemgetter('context')) |              | Passthrough |                \n",
            "     +-------------------------------+              +-------------+                \n",
            "                              ****               ****                              \n",
            "                                  ***         ***                                  \n",
            "                                     **     **                                     \n",
            "                           +-------------------------+                             \n",
            "                           | Parallel<context>Output |                             \n",
            "                           +-------------------------+                             \n",
            "                                         *                                         \n",
            "                                         *                                         \n",
            "                                         *                                         \n",
            "                       +---------------------------------+                         \n",
            "                       | Parallel<response,context>Input |                         \n",
            "                       +---------------------------------+                         \n",
            "                             ***                  ****                             \n",
            "                         ****                         ***                          \n",
            "                       **                                ****                      \n",
            "         +--------------------+                              **                    \n",
            "         | ChatPromptTemplate |                               *                    \n",
            "         +--------------------+                               *                    \n",
            "                    *                                         *                    \n",
            "                    *                                         *                    \n",
            "                    *                                         *                    \n",
            "             +------------+                  +-------------------------------+     \n",
            "             | ChatOpenAI |                  | Lambda(itemgetter('context')) |     \n",
            "             +------------+**                +-------------------------------+     \n",
            "                             ***                  ***                              \n",
            "                                ****          ****                                 \n",
            "                                    **      **                                     \n",
            "                       +----------------------------------+                        \n",
            "                       | Parallel<response,context>Output |                        \n",
            "                       +----------------------------------+                        \n"
          ]
        }
      ],
      "source": [
        "print(retrieval_augmented_qa_chain.get_graph().draw_ascii())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zO69de-F-oMD"
      },
      "source": [
        "Let's test it out!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FS5NxC6UyU2",
        "outputId": "db9953a2-758d-4723-cd95-e980a47715d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Get right to the center of the industry.\n"
          ]
        }
      ],
      "source": [
        "question = \"What is a rule of thumb for selecting an industry to invest in?\"\n",
        "\n",
        "result = retrieval_augmented_qa_chain.invoke({\"question\" : question})\n",
        "\n",
        "print(result[\"response\"].content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIuHVGPOO9P2",
        "outputId": "24ce3524-9284-4eea-f78b-4329a615d321"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I don't know.\n",
            "[Document(page_content='ask if you can call them again if things change.\\nTrust me ‚Äî they‚Äôd much rather be saying ‚Äúyes‚Äù than ‚Äúno‚Äù ‚Äî\\nthey need all the good investments they can get.\\nSecond, consider the environment.', metadata={'source': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'file_path': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'page': 15, 'total_pages': 195, 'format': 'PDF 1.3', 'title': 'The Pmarca Blog Archives', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Mac OS X 10.10 Quartz PDFContext', 'creationDate': \"D:20150110020418Z00'00'\", 'modDate': \"D:20150110020418Z00'00'\", 'trapped': '', '_id': '85097ac9c48b4f3b802d6b22f00d86dc', '_collection_name': 'PMarca Blogs'}), Document(page_content='watching carefully ‚Äî if everyone agrees right up front that\\nwhatever you are doing makes total sense, it probably isn‚Äôt a new\\nand radical enough idea to justify a new company.', metadata={'source': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'file_path': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'page': 152, 'total_pages': 195, 'format': 'PDF 1.3', 'title': 'The Pmarca Blog Archives', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Mac OS X 10.10 Quartz PDFContext', 'creationDate': \"D:20150110020418Z00'00'\", 'modDate': \"D:20150110020418Z00'00'\", 'trapped': '', '_id': 'cb941e9564c0444683337e5e6d64a850', '_collection_name': 'PMarca Blogs'}), Document(page_content='Third rule:\\nIn a rapidly changing Held like technology, the best place to\\nget experience when you‚Äôre starting out is in younger, high-\\ngrowth companies.', metadata={'source': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'file_path': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'page': 127, 'total_pages': 195, 'format': 'PDF 1.3', 'title': 'The Pmarca Blog Archives', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Mac OS X 10.10 Quartz PDFContext', 'creationDate': \"D:20150110020418Z00'00'\", 'modDate': \"D:20150110020418Z00'00'\", 'trapped': '', '_id': 'ea84cb607bca4c6bb1b6a21b9ecf64ef', '_collection_name': 'PMarca Blogs'}), Document(page_content='the existing order ‚Äî and make sure that those forces of change\\nhave a reasonable chance at succeeding.\\nSecond rule of thumb:\\nOnce you have picked an industry, get right to the center of it', metadata={'source': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'file_path': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'page': 125, 'total_pages': 195, 'format': 'PDF 1.3', 'title': 'The Pmarca Blog Archives', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Mac OS X 10.10 Quartz PDFContext', 'creationDate': \"D:20150110020418Z00'00'\", 'modDate': \"D:20150110020418Z00'00'\", 'trapped': '', '_id': '036019aea40b49efa31034a9e04ec300', '_collection_name': 'PMarca Blogs'})]\n"
          ]
        }
      ],
      "source": [
        "question = \"What did Pink Floyd have to say about how to proceed when investing in a new industry?\"\n",
        "\n",
        "result = retrieval_augmented_qa_chain.invoke({\"question\" : question})\n",
        "\n",
        "print(result[\"response\"].content)\n",
        "print(result[\"context\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-XYZueEP42k"
      },
      "source": [
        "We can already see that there are some improvements we could make here.\n",
        "\n",
        "For now, let's switch gears to RAGAS to see how we can leverage that tool to provide us insight into how our pipeline is performing!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOECHyzHRqDw"
      },
      "source": [
        "## Task 4: Synthetic Dataset Generation for Evaluation using Ragas\n",
        "\n",
        "Ragas is a powerful library that lets us evaluate our RAG pipeline by collecting input/output/context triplets and obtaining metrics relating to a number of different aspects of our RAG pipeline.\n",
        "\n",
        "We'll be evaluating on every core metric today, but in order to do that - we'll need to create a test set. Luckily for us, Ragas can do that directly!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqXQ0jweWJOu"
      },
      "source": [
        "### Synthetic Test Set Generation\n",
        "\n",
        "We can leverage Ragas' [`Synthetic Test Data generation`](https://docs.ragas.io/en/stable/concepts/testset_generation.html) functionality to generate our own synthetic QC pairs - as well as a synthetic ground truth - quite easily!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "nVk5SlU9znXe"
      },
      "outputs": [],
      "source": [
        "loader = PyMuPDFLoader(\n",
        "    \"https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf\",\n",
        ")\n",
        "\n",
        "eval_documents = loader.load()\n",
        "\n",
        "text_splitter_eval = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 600,\n",
        "    chunk_overlap = 50\n",
        ")\n",
        "\n",
        "eval_documents = text_splitter_eval.split_documents(eval_documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7rOQkxhzrq3"
      },
      "source": [
        "####‚ùì Question #2:\n",
        "\n",
        "Why is it important to split our documents using different parameters when creating our synthetic data?\n",
        "\n",
        "> **Answer:** We want to split our documents using different parameters when creating synthetic data \n",
        "> - Purpose of synthetic data is different than the documents used for context setting. Synthetic needs to represent wide variety of scenarios that the model and RAG encounters than what it has been optimized for. So, the different parameters allows us to drive evaluation using different set of data\n",
        "> - Retrieval data for context setting needs to be optimized for retrieval and locking in a single idea or concept inside one instance without filling up memory unnecessarily. This is different from the purpose of synthetic data. So, the parameters are different."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiAPYw-hz-zo",
        "outputId": "fc8c6829-5c53-4eb1-8407-1545f5a7d023"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "624"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(eval_documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYCrVMW9Blda"
      },
      "source": [
        "\n",
        "> NOTE: üõë Using this notebook as presented will occur a charge of ~$3USD from OpenAI usage. Most of this cost is produced by the Synthetic Data Generation step - if you want to reduce costs, please use the provided commented code to leverage GPT-3.5-Turbo as the critic_llm. If you're attempting to create a lot of samples please be aware of cost, as well as rate limits. üõë"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f75fdd56268a4b83a7fb7e4a3b2cce82",
            "1fb5a4b71deb406fa2f342c88b9e4e1d",
            "37ec9b5c847749439d7c155ac3b1ec68",
            "1317f4e20e1c4574a360345b427c3e8a",
            "2aa53858803d4ad39113009d86dd67fc",
            "7e1d22c19aff4c768d643c249e425d00",
            "3a498872a68049329b4d206629b9b3bf",
            "89a7c333d0b241169dc29ed998b2c9c4",
            "88c8557741734e59a6099bb5fa260f6e",
            "92ef10fab64c4f40a93da3d31b572016",
            "3b43c3f561e34d019007ac9a0125b28d",
            "05ab48866b5d49df9567ce9cbda5ee2e",
            "49c1ef316e404052a7c8528781db3f9a",
            "2dcb3e2fdf164e35a27a79cfae65933a",
            "202f4244384a4501bfc1ffa50af96a1f",
            "d93698b0506743ff98fdb998cfb7080a",
            "19acd28bfa2e4a7a83bc42faea5de770",
            "356b929fa8dc42538767c58dcce12217",
            "60a663f8736a43bcb47ac6c5f37ec597",
            "e6edc46811064de2b74a6a477c4a44b7",
            "a10a7577a99b4683a1d59a09d88f93a1",
            "444bc7dae1aa4e098b79655428599310"
          ]
        },
        "id": "IXc6sMglSej_",
        "outputId": "1d4904f0-9674-448a-9af3-f99da62cc8f3"
      },
      "outputs": [],
      "source": [
        "from ragas.testset.generator import TestsetGenerator\n",
        "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "\n",
        "#Reducing to first 500 rows to avoid OpenAI rate limits\n",
        "eval_documents = eval_documents[0:500]\n",
        "generator_llm = ChatOpenAI(model=\"gpt-3.5-turbo-16k\")\n",
        "# critic_llm = ChatOpenAI(model=\"gpt-3.5-turbo\") <--- If you don't have GPT-4 access, or to reduce cost/rate limiting issues.\n",
        "critic_llm = ChatOpenAI(model=\"gpt-4o\")\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "generator = TestsetGenerator.from_langchain(\n",
        "    generator_llm,\n",
        "    critic_llm,\n",
        "    embeddings\n",
        ")\n",
        "\n",
        "distributions = {\n",
        "    simple: 0.5,\n",
        "    multi_context: 0.4,\n",
        "    reasoning: 0.1\n",
        "}\n",
        "\n",
        "testset = generator.generate_with_langchain_docs(eval_documents, 20, distributions, is_async = False)\n",
        "testset.to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOIGT0XLz8ze"
      },
      "source": [
        "####‚ùì Question #3:\n",
        "\n",
        "`{simple: 0.5, reasoning: 0.25, multi_context: 0.25}`\n",
        "\n",
        "What exactly does this mapping refer to?\n",
        "\n",
        "> **Answer:** \n",
        "> 1. `simple` refers to basic retrieval and generation. It evaulating simple question capabilities. \n",
        "> 2. `reasoning` refers to more complex task that need reasoning beyond simple question, answering and solving multiple-step process and drawing inferences, not directly evident in the data.\n",
        "> 3. `multi_context` refers to system ability to synthesize multiple sources or contexts of data. It signifies ability to draw data from other documents and domains to provide an answer.\n",
        "\n",
        "> NOTE: Check out the Ragas documentation on this generation process [here](https://docs.ragas.io/en/stable/concepts/testset_generation.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MemL406rUzBu"
      },
      "source": [
        "Let's look at the output and see what we can learn about it!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaCDdImVU15s",
        "outputId": "31efbb94-f09d-4d50-8c6e-59202aaeb5c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataRow(question='How does winning impact the retention of great people in companies?', contexts=['Part 2: Retaining great people\\nThis post is about retaining great people, particularly at big com-\\npanies in industries like technology, where stock options matter\\nand where people can relatively easily move from one company\\nto another.\\nActually, I lied. This post isn‚Äôt really about retention at all.\\nIt‚Äôs about winning.\\nLet me explain:\\nCompanies that are winning ‚Äî even really big, old ones ‚Äî never\\nhave a retention problem. Everyone wants to stay, and when some-\\none does leave, it‚Äôs really easy to get someone great to take her\\nplace.\\nCompanies that have a retention problem usually have a win-'], ground_truth=\"Companies that are winning never have a retention problem. Everyone wants to stay, and when someone does leave, it's really easy to get someone great to take her place.\", evolution_type='simple', metadata=[{'source': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'file_path': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'page': 90, 'total_pages': 195, 'format': 'PDF 1.3', 'title': 'The Pmarca Blog Archives', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Mac OS X 10.10 Quartz PDFContext', 'creationDate': \"D:20150110020418Z00'00'\", 'modDate': \"D:20150110020418Z00'00'\", 'trapped': ''}])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testset.test_data[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrPsVwUAWFWB"
      },
      "source": [
        "### Generating Responses with RAG Pipeline\n",
        "\n",
        "Now that we have some QC pairs, and some ground truths, let's evaluate our RAG pipeline using Ragas.\n",
        "\n",
        "The process is, again, quite straightforward - thanks to Ragas and LangChain!\n",
        "\n",
        "Let's start by extracting our questions and ground truths from our create testset.\n",
        "\n",
        "We can start by converting our test dataset into a Pandas DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "frvzu1YxX8kY"
      },
      "outputs": [],
      "source": [
        "test_df = testset.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GFKMIY8IZU8m",
        "outputId": "ed137f4f-df2c-41fa-d868-802d30076ea0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>contexts</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>evolution_type</th>\n",
              "      <th>metadata</th>\n",
              "      <th>episode_done</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How does winning impact the retention of great...</td>\n",
              "      <td>[Part 2: Retaining great people\\nThis post is ...</td>\n",
              "      <td>Companies that are winning never have a retent...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How does the constant change in the world make...</td>\n",
              "      <td>[Part 1: Opportunity\\nThe Hrst rule of career ...</td>\n",
              "      <td>The constant change in the world makes it diff...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the concept of \"Task Relevant Maturity...</td>\n",
              "      <td>[SpeciXcally, there are times and situations w...</td>\n",
              "      <td>The concept of 'Task Relevant Maturity' refers...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Why is it important to focus on strength rathe...</td>\n",
              "      <td>[manage executives. It turns out that just abo...</td>\n",
              "      <td>When managing executives, it is important to f...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What analogy is used to describe the interacti...</td>\n",
              "      <td>[pany‚Äôs permission to do something. Or maybe a...</td>\n",
              "      <td>The analogy used to describe the interaction b...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Why do some entrepreneurs choose to hold back ...</td>\n",
              "      <td>[need it.\\nWhat if you don‚Äôt want to raise tha...</td>\n",
              "      <td>Some entrepreneurs choose to hold back on rais...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Why is it important to seek out and create opp...</td>\n",
              "      <td>[sented with an opportunity like one of the ab...</td>\n",
              "      <td>Both opportunities that present themselves and...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Why is it important to be in a dynamic and exc...</td>\n",
              "      <td>[they might be.\\nNever worry about being a sma...</td>\n",
              "      <td>Being in a dynamic and exciting pond is import...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>What are some examples of situations where mis...</td>\n",
              "      <td>[‚Äî put yourself in situations where you will s...</td>\n",
              "      <td>missing a critical piece of information in a f...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>How does Nassim Nicholas Taleb describe the co...</td>\n",
              "      <td>[do, just sit down and tease apart the risks ‚Äî...</td>\n",
              "      <td>Many people do not realize they are getting a ...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>What are the advantages of having reputable co...</td>\n",
              "      <td>[training for a marathon while wearing ankle w...</td>\n",
              "      <td>Having reputable companies like Silicon Graphi...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>What are the potential long-term repercussions...</td>\n",
              "      <td>[senior person at your Xrm? You risk exhaustin...</td>\n",
              "      <td>The potential long-term repercussions of overe...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>How do technical degrees demonstrate commitmen...</td>\n",
              "      <td>[‚Ä¢\\nPlus, technical degrees teach you how thin...</td>\n",
              "      <td>Technical degrees demonstrate commitment to fu...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>What is Silicon Valley's impact on startup fun...</td>\n",
              "      <td>[in Silicon Valley and handful of other places...</td>\n",
              "      <td>Silicon Valley is one of the places where the ...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>What undergraduate degrees are valuable in bus...</td>\n",
              "      <td>[that for what it‚Äôs worth.\\nIf you don‚Äôt have ...</td>\n",
              "      <td>An undergraduate degree in engineering or math...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>What are the two crucial career opportunities ...</td>\n",
              "      <td>[sented with an opportunity like one of the ab...</td>\n",
              "      <td>The two crucial career opportunities are those...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>What impact does a company's declining stock v...</td>\n",
              "      <td>[ning problem. Or rather, a ‚Äúnot winning‚Äù prob...</td>\n",
              "      <td>nan</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>If there is a lack of capable individuals on t...</td>\n",
              "      <td>[Part 9: How to hire a professional\\nCEO\\nDon‚Äô...</td>\n",
              "      <td>The company should be sold.</td>\n",
              "      <td>reasoning</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Why is it important to understand an executive...</td>\n",
              "      <td>[can Xgure out how to build and run an organiz...</td>\n",
              "      <td>nan</td>\n",
              "      <td>reasoning</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             question  \\\n",
              "0   How does winning impact the retention of great...   \n",
              "1   How does the constant change in the world make...   \n",
              "2   What is the concept of \"Task Relevant Maturity...   \n",
              "3   Why is it important to focus on strength rathe...   \n",
              "4   What analogy is used to describe the interacti...   \n",
              "5   Why do some entrepreneurs choose to hold back ...   \n",
              "6   Why is it important to seek out and create opp...   \n",
              "7   Why is it important to be in a dynamic and exc...   \n",
              "8   What are some examples of situations where mis...   \n",
              "9   How does Nassim Nicholas Taleb describe the co...   \n",
              "10  What are the advantages of having reputable co...   \n",
              "11  What are the potential long-term repercussions...   \n",
              "12  How do technical degrees demonstrate commitmen...   \n",
              "13  What is Silicon Valley's impact on startup fun...   \n",
              "14  What undergraduate degrees are valuable in bus...   \n",
              "15  What are the two crucial career opportunities ...   \n",
              "16  What impact does a company's declining stock v...   \n",
              "17  If there is a lack of capable individuals on t...   \n",
              "18  Why is it important to understand an executive...   \n",
              "\n",
              "                                             contexts  \\\n",
              "0   [Part 2: Retaining great people\\nThis post is ...   \n",
              "1   [Part 1: Opportunity\\nThe Hrst rule of career ...   \n",
              "2   [SpeciXcally, there are times and situations w...   \n",
              "3   [manage executives. It turns out that just abo...   \n",
              "4   [pany‚Äôs permission to do something. Or maybe a...   \n",
              "5   [need it.\\nWhat if you don‚Äôt want to raise tha...   \n",
              "6   [sented with an opportunity like one of the ab...   \n",
              "7   [they might be.\\nNever worry about being a sma...   \n",
              "8   [‚Äî put yourself in situations where you will s...   \n",
              "9   [do, just sit down and tease apart the risks ‚Äî...   \n",
              "10  [training for a marathon while wearing ankle w...   \n",
              "11  [senior person at your Xrm? You risk exhaustin...   \n",
              "12  [‚Ä¢\\nPlus, technical degrees teach you how thin...   \n",
              "13  [in Silicon Valley and handful of other places...   \n",
              "14  [that for what it‚Äôs worth.\\nIf you don‚Äôt have ...   \n",
              "15  [sented with an opportunity like one of the ab...   \n",
              "16  [ning problem. Or rather, a ‚Äúnot winning‚Äù prob...   \n",
              "17  [Part 9: How to hire a professional\\nCEO\\nDon‚Äô...   \n",
              "18  [can Xgure out how to build and run an organiz...   \n",
              "\n",
              "                                         ground_truth evolution_type  \\\n",
              "0   Companies that are winning never have a retent...         simple   \n",
              "1   The constant change in the world makes it diff...         simple   \n",
              "2   The concept of 'Task Relevant Maturity' refers...         simple   \n",
              "3   When managing executives, it is important to f...         simple   \n",
              "4   The analogy used to describe the interaction b...         simple   \n",
              "5   Some entrepreneurs choose to hold back on rais...         simple   \n",
              "6   Both opportunities that present themselves and...         simple   \n",
              "7   Being in a dynamic and exciting pond is import...         simple   \n",
              "8   missing a critical piece of information in a f...         simple   \n",
              "9   Many people do not realize they are getting a ...         simple   \n",
              "10  Having reputable companies like Silicon Graphi...  multi_context   \n",
              "11  The potential long-term repercussions of overe...  multi_context   \n",
              "12  Technical degrees demonstrate commitment to fu...  multi_context   \n",
              "13  Silicon Valley is one of the places where the ...  multi_context   \n",
              "14  An undergraduate degree in engineering or math...  multi_context   \n",
              "15  The two crucial career opportunities are those...  multi_context   \n",
              "16                                                nan  multi_context   \n",
              "17                        The company should be sold.      reasoning   \n",
              "18                                                nan      reasoning   \n",
              "\n",
              "                                             metadata  episode_done  \n",
              "0   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "1   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "2   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "3   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "4   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "5   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "6   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "7   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "8   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "9   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "10  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "11  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "12  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "13  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "14  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "15  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "16  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "17  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "18  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  "
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "xAiXbVmLYSoC"
      },
      "outputs": [],
      "source": [
        "test_questions = test_df[\"question\"].values.tolist()\n",
        "test_groundtruths = test_df[\"ground_truth\"].values.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aE5rfMLfbqKH"
      },
      "source": [
        "Now we'll generate responses using our RAG pipeline using the questions we've generated - we'll also need to collect our retrieved contexts for each question.\n",
        "\n",
        "We'll do this in a simple loop to see exactly what's happening!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "9_AayvT1dAQN"
      },
      "outputs": [],
      "source": [
        "answers = []\n",
        "contexts = []\n",
        "\n",
        "for question in test_questions:\n",
        "  response = retrieval_augmented_qa_chain.invoke({\"question\" : question})\n",
        "  answers.append(response[\"response\"].content)\n",
        "  contexts.append([context.page_content for context in response[\"context\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opHaHmYDeBfC"
      },
      "source": [
        "Now we can wrap our information in a Hugging Face dataset for use in the Ragas library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "fY48YZITeHy-"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "# Truncating to avoid OpenAI Rate limits\n",
        "TRUNC_SIZE = 10\n",
        "response_dataset = Dataset.from_dict({\n",
        "    \"question\" : test_questions[0:TRUNC_SIZE],\n",
        "    \"answer\" : answers[0:TRUNC_SIZE],\n",
        "    \"contexts\" : contexts[0:TRUNC_SIZE],\n",
        "    \"ground_truth\" : test_groundtruths[0:TRUNC_SIZE]\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmeVvQaZeogE"
      },
      "source": [
        "Let's take a peek and see what that looks like!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOpydvc8eqNM",
        "outputId": "f924b59d-eb6b-4c1a-9d18-f545c4e2c724"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'question': 'How does winning impact the retention of great people in companies?',\n",
              " 'answer': 'Winning impacts the retention of great people in companies because great people want to work at a winner.',\n",
              " 'contexts': ['The only way a company in that situation can retain great peo-\\nple is to start winning again.\\nGreat people want to work at a winner.\\nAll the raises, perks, and HR-sponsored ‚Äúcompany values‚Äù draa-',\n",
              "  'and where people can relatively easily move from one company\\nto another.\\nActually, I lied. This post isn‚Äôt really about retention at all.\\nIt‚Äôs about winning.\\nLet me explain:',\n",
              "  'one does leave, it‚Äôs really easy to get someone great to take her\\nplace.\\nCompanies that have a retention problem usually have a win-\\nning problem. Or rather, a ‚Äúnot winning‚Äù problem.',\n",
              "  'Part 2: Retaining great people\\nThis post is about retaining great people, particularly at big com-\\npanies in industries like technology, where stock options matter'],\n",
              " 'ground_truth': \"Companies that are winning never have a retention problem. Everyone wants to stay, and when someone does leave, it's really easy to get someone great to take her place.\"}"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response_dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM4fmAnsBmL2"
      },
      "source": [
        "# ü§ù Breakout Room Part #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbsFm5FievJI"
      },
      "source": [
        "## Task 1: Evaluating our Pipeline with Ragas\n",
        "\n",
        "Now that we have our response dataset - we can finally get into the \"meat\" of Ragas - evaluation!\n",
        "\n",
        "First, we'll import the desired metrics, then we can use them to evaluate our created dataset!\n",
        "\n",
        "Check out the specific metrics we'll be using in the Ragas documentation:\n",
        "\n",
        "- [Faithfulness](https://docs.ragas.io/en/stable/concepts/metrics/faithfulness.html)\n",
        "- [Answer Relevancy](https://docs.ragas.io/en/stable/concepts/metrics/answer_relevance.html)\n",
        "- [Context Precision](https://docs.ragas.io/en/stable/concepts/metrics/context_precision.html)\n",
        "- [Context Recall](https://docs.ragas.io/en/stable/concepts/metrics/context_recall.html)\n",
        "- [Answer Correctness](https://docs.ragas.io/en/stable/concepts/metrics/answer_correctness.html)\n",
        "\n",
        "See the accompanied presentation for more in-depth explanations about each of the metrics!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "R2PXwyt8e5aW"
      },
      "outputs": [],
      "source": [
        "from ragas import evaluate\n",
        "from ragas.metrics import (\n",
        "    faithfulness,\n",
        "    answer_relevancy,\n",
        "    answer_correctness,\n",
        "    context_recall,\n",
        "    context_precision,\n",
        ")\n",
        "\n",
        "metrics = [\n",
        "    faithfulness,\n",
        "    answer_relevancy,\n",
        "    context_recall,\n",
        "    context_precision,\n",
        "    answer_correctness,\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10\n"
          ]
        }
      ],
      "source": [
        "print(response_dataset.num_rows)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx-vlsx_hrtV"
      },
      "source": [
        "All that's left to do is call \"evaluate\" and away we go!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "32514310070a426ea247c9f1bc66b630",
            "3e7520df71de40e0af5589b6aeb95171",
            "05390d20f1b445b5b02529ee7a99f6d6",
            "3380693903474d2585638f7e3458fcd6",
            "1d43002974f24e8a8b6961cddc04ce47",
            "97abe811c89c44dcacd7e39074d22546",
            "87a3d4b2ed5f4f1ca895c6a1981eb847",
            "589c2004f5504a239615dec8671785d0",
            "25d3337c457f4c748ed8bf78f5a27fe8",
            "31064d2adec14238a609d3f9791c64f3",
            "4f482b8ce7a54c1787394fb7d90391a0"
          ]
        },
        "id": "DhlcfJ4lgYVI",
        "outputId": "85fa2a99-7506-45d1-a674-ca9f55372264"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:25<00:00,  1.72s/it]\n"
          ]
        }
      ],
      "source": [
        "results = evaluate(response_dataset, metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqPArpSrgwDD",
        "outputId": "e8f3cb2f-8a38-47a5-f54d-ec80eaca8448"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'faithfulness': 0.8500, 'answer_relevancy': 0.9336, 'context_recall': 0.6667, 'context_precision': 0.7556, 'answer_correctness': 0.5340}"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2nsGzj8DhP9E",
        "outputId": "a10d6394-0ab7-48bf-96c5-acfc5992622f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>contexts</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>faithfulness</th>\n",
              "      <th>answer_relevancy</th>\n",
              "      <th>context_recall</th>\n",
              "      <th>context_precision</th>\n",
              "      <th>answer_correctness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How does winning impact the retention of great...</td>\n",
              "      <td>Winning impacts the retention of great people ...</td>\n",
              "      <td>[The only way a company in that situation can ...</td>\n",
              "      <td>Companies that are winning never have a retent...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.951926</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.226177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How does the constant change in the world make...</td>\n",
              "      <td>The constant change in the world makes it diff...</td>\n",
              "      <td>[Trying to plan your career is an exercise in ...</td>\n",
              "      <td>The constant change in the world makes it diff...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.943412</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.366915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the concept of \"Task Relevant Maturity...</td>\n",
              "      <td>The concept of \"Task Relevant Maturity\" is des...</td>\n",
              "      <td>[book High Output Management, where he describ...</td>\n",
              "      <td>The concept of 'Task Relevant Maturity' refers...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.933060</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.847602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Why is it important to focus on strength rathe...</td>\n",
              "      <td>It is important to focus on strength rather th...</td>\n",
              "      <td>[back ‚Äî perhaps abstractly ‚Äî about all of her ...</td>\n",
              "      <td>When managing executives, it is important to f...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.912358</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.406620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What analogy is used to describe the interacti...</td>\n",
              "      <td>The analogy used is \"there is potentially a to...</td>\n",
              "      <td>[There are times in the life of a startup when...</td>\n",
              "      <td>The analogy used to describe the interaction b...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.883689</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.206945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Why do some entrepreneurs choose to hold back ...</td>\n",
              "      <td>Some entrepreneurs choose to hold back on rais...</td>\n",
              "      <td>[a higher valuation, and give away less of the...</td>\n",
              "      <td>Some entrepreneurs choose to hold back on rais...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.859759</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.887176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Why is it important to seek out and create opp...</td>\n",
              "      <td>It is important to seek out and create opportu...</td>\n",
              "      <td>[One of the single best ways you can maximize ...</td>\n",
              "      <td>Both opportunities that present themselves and...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.732039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Why is it important to be in a dynamic and exc...</td>\n",
              "      <td>It is important to be in a dynamic and excitin...</td>\n",
              "      <td>[Third rule:\\nIn a rapidly changing Held like ...</td>\n",
              "      <td>Being in a dynamic and exciting pond is import...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.997891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>What are some examples of situations where mis...</td>\n",
              "      <td>Launching a product and seeing it tank, being ...</td>\n",
              "      <td>[project, launching a product and seeing it ta...</td>\n",
              "      <td>missing a critical piece of information in a f...</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.853706</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.206630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>How does Nassim Nicholas Taleb describe the co...</td>\n",
              "      <td>Nassim Nicholas Taleb describes the concept of...</td>\n",
              "      <td>[of a great opportunity. They oaen won‚Äôt.\\nOne...</td>\n",
              "      <td>Many people do not realize they are getting a ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.997956</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.461882</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question  \\\n",
              "0  How does winning impact the retention of great...   \n",
              "1  How does the constant change in the world make...   \n",
              "2  What is the concept of \"Task Relevant Maturity...   \n",
              "3  Why is it important to focus on strength rathe...   \n",
              "4  What analogy is used to describe the interacti...   \n",
              "5  Why do some entrepreneurs choose to hold back ...   \n",
              "6  Why is it important to seek out and create opp...   \n",
              "7  Why is it important to be in a dynamic and exc...   \n",
              "8  What are some examples of situations where mis...   \n",
              "9  How does Nassim Nicholas Taleb describe the co...   \n",
              "\n",
              "                                              answer  \\\n",
              "0  Winning impacts the retention of great people ...   \n",
              "1  The constant change in the world makes it diff...   \n",
              "2  The concept of \"Task Relevant Maturity\" is des...   \n",
              "3  It is important to focus on strength rather th...   \n",
              "4  The analogy used is \"there is potentially a to...   \n",
              "5  Some entrepreneurs choose to hold back on rais...   \n",
              "6  It is important to seek out and create opportu...   \n",
              "7  It is important to be in a dynamic and excitin...   \n",
              "8  Launching a product and seeing it tank, being ...   \n",
              "9  Nassim Nicholas Taleb describes the concept of...   \n",
              "\n",
              "                                            contexts  \\\n",
              "0  [The only way a company in that situation can ...   \n",
              "1  [Trying to plan your career is an exercise in ...   \n",
              "2  [book High Output Management, where he describ...   \n",
              "3  [back ‚Äî perhaps abstractly ‚Äî about all of her ...   \n",
              "4  [There are times in the life of a startup when...   \n",
              "5  [a higher valuation, and give away less of the...   \n",
              "6  [One of the single best ways you can maximize ...   \n",
              "7  [Third rule:\\nIn a rapidly changing Held like ...   \n",
              "8  [project, launching a product and seeing it ta...   \n",
              "9  [of a great opportunity. They oaen won‚Äôt.\\nOne...   \n",
              "\n",
              "                                        ground_truth  faithfulness  \\\n",
              "0  Companies that are winning never have a retent...           1.0   \n",
              "1  The constant change in the world makes it diff...           1.0   \n",
              "2  The concept of 'Task Relevant Maturity' refers...           1.0   \n",
              "3  When managing executives, it is important to f...           1.0   \n",
              "4  The analogy used to describe the interaction b...           1.0   \n",
              "5  Some entrepreneurs choose to hold back on rais...           1.0   \n",
              "6  Both opportunities that present themselves and...           1.0   \n",
              "7  Being in a dynamic and exciting pond is import...           1.0   \n",
              "8  missing a critical piece of information in a f...           0.5   \n",
              "9  Many people do not realize they are getting a ...           0.0   \n",
              "\n",
              "   answer_relevancy  context_recall  context_precision  answer_correctness  \n",
              "0          0.951926        1.000000           0.805556            0.226177  \n",
              "1          0.943412        1.000000           1.000000            0.366915  \n",
              "2          0.933060        1.000000           0.916667            0.847602  \n",
              "3          0.912358        0.333333           0.916667            0.406620  \n",
              "4          0.883689        0.000000           0.583333            0.206945  \n",
              "5          0.859759        1.000000           0.916667            0.887176  \n",
              "6          1.000000        1.000000           0.916667            0.732039  \n",
              "7          1.000000        1.000000           0.916667            0.997891  \n",
              "8          0.853706        0.333333           0.000000            0.206630  \n",
              "9          0.997956        0.000000           0.583333            0.461882  "
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_df = results.to_pandas()\n",
        "results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWfiu_pLh3JL"
      },
      "source": [
        "## Task 2: Making Adjustments to our RAG Pipeline\n",
        "\n",
        "Now that we have established a baseline - we can see how any changes impact our pipeline's performance!\n",
        "\n",
        "Let's modify our retriever and see how that impacts our Ragas metrics!\n",
        "\n",
        "> NOTE: MultiQueryRetriever is expanded on [here](https://python.langchain.com/docs/modules/data_connection/retrievers/MultiQueryRetriever) but for now, the implementation is not important to our lesson!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "nKIuM336isBL"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import MultiQueryRetriever\n",
        "\n",
        "advanced_retriever = MultiQueryRetriever.from_llm(retriever=retriever, llm=primary_qa_llm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82rcj3L-i_c8"
      },
      "source": [
        "We'll also re-create our RAG pipeline using the abstractions that come packaged with LangChain v0.1.0!\n",
        "\n",
        "First, let's create a chain to \"stuff\" our documents into our context!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "EfdCgTw7jC4i"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "\n",
        "document_chain = create_stuff_documents_chain(primary_qa_llm, retrieval_qa_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozYl5WdPnvLu"
      },
      "source": [
        "Next, we'll create the retrieval chain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "9AK7wHVnn0U3"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "\n",
        "retrieval_chain = create_retrieval_chain(advanced_retriever, document_chain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "cmKORMfMoCjL"
      },
      "outputs": [],
      "source": [
        "response = retrieval_chain.invoke({\"input\": \"Who is Taylor Swift fueding with?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICMsUWbWoOpf",
        "outputId": "1c2a8c65-0da8-44ef-d6e4-79dcca738777"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I'm sorry, but based on the context provided, I do not have information about any feud involving Taylor Swift.\n"
          ]
        }
      ],
      "source": [
        "print(response[\"answer\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "5s8ZGasYoVi6"
      },
      "outputs": [],
      "source": [
        "response = retrieval_chain.invoke({\"input\": \"Why are they fueding?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADNCdW4hoYT8",
        "outputId": "40860a4e-75fb-486e-b1e6-34a7eb2c5295"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The text does not provide any information about a feud or conflict between individuals or groups. It mainly discusses factors that contribute to success or failure in business, human behavior, and decision-making processes.\n"
          ]
        }
      ],
      "source": [
        "print(response[\"answer\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxkU0HdpoaiE"
      },
      "source": [
        "Well, just from those responses this chain *feels* better - but lets see how it performs on our eval!\n",
        "\n",
        "Let's do the same process we did before to collect our pipeline's contexts and answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "kO8cWxn2oinT"
      },
      "outputs": [],
      "source": [
        "answers = []\n",
        "contexts = []\n",
        "\n",
        "for question in test_questions:\n",
        "  response = retrieval_chain.invoke({\"input\" : question})\n",
        "  answers.append(response[\"answer\"])\n",
        "  contexts.append([context.page_content for context in response[\"context\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgagfhPUtM2j"
      },
      "source": [
        "Now we can convert this into a dataset, just like we did before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "5FcllGeSovP8"
      },
      "outputs": [],
      "source": [
        "# Reduced size to fit OpenAI rate limits\n",
        "REDUCED_SIZE = int(TRUNC_SIZE/2)\n",
        "response_dataset_advanced_retrieval = Dataset.from_dict({\n",
        "    \"question\" : test_questions[0:REDUCED_SIZE],\n",
        "    \"answer\" : answers[0:REDUCED_SIZE],\n",
        "    \"contexts\" : contexts[0:REDUCED_SIZE],\n",
        "    \"ground_truth\" : test_groundtruths[0:REDUCED_SIZE]\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dELYabwktR2C"
      },
      "source": [
        "Let's evaluate on the same metrics we did for the first pipeline and see how it does!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "831b4dab6ff94d239d2824d390e01308",
            "4cefefc6cf714a68924e1b8d5e59aba9",
            "fd7f5542a22d44388dda12ca19443a1f",
            "93bf9b194c04460abffa192c19bcf67b",
            "83985f58744a46cfbd001ce5957f3e4a",
            "5c2b92989d7448e9bf65306c4f2f7d93",
            "a34b3906cd514234a115c7bf6757ca9d",
            "a03fefb9fa5a40ff947dc4ccd3c80318",
            "40343486e3ea4e5fae55b5a528f139d8",
            "cee2268aa21643e6ad77117c67ec1600",
            "c79f28da88f44d69aa87905c089df333"
          ]
        },
        "id": "d7uHseWJo2TU",
        "outputId": "8facfba9-467a-4129-b381-ddbd0a952f28"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:16<00:00,  1.55it/s]\n"
          ]
        }
      ],
      "source": [
        "advanced_retrieval_results = evaluate(response_dataset_advanced_retrieval, metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JsFd0uDd2n5E",
        "outputId": "0922ab45-c16a-48c4-c9c2-3647ff130391"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>contexts</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>faithfulness</th>\n",
              "      <th>answer_relevancy</th>\n",
              "      <th>context_recall</th>\n",
              "      <th>context_precision</th>\n",
              "      <th>answer_correctness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How does winning impact the retention of great...</td>\n",
              "      <td>Winning is crucial for retaining great people ...</td>\n",
              "      <td>[The only way a company in that situation can ...</td>\n",
              "      <td>Companies that are winning never have a retent...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.927039</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.688864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How does the constant change in the world make...</td>\n",
              "      <td>The constant change in the world makes it diff...</td>\n",
              "      <td>[tunity, someone else generally will and it wi...</td>\n",
              "      <td>The constant change in the world makes it diff...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.964069</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.645833</td>\n",
              "      <td>0.333131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the concept of \"Task Relevant Maturity...</td>\n",
              "      <td>The concept of \"Task Relevant Maturity\" refers...</td>\n",
              "      <td>[book High Output Management, where he describ...</td>\n",
              "      <td>The concept of 'Task Relevant Maturity' refers...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.937940</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.847315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Why is it important to focus on strength rathe...</td>\n",
              "      <td>It is important to focus on strength rather th...</td>\n",
              "      <td>[back ‚Äî perhaps abstractly ‚Äî about all of her ...</td>\n",
              "      <td>When managing executives, it is important to f...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.912358</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.616126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What analogy is used to describe the interacti...</td>\n",
              "      <td>The analogy used to describe the interaction b...</td>\n",
              "      <td>[investors, potential customers, potential par...</td>\n",
              "      <td>The analogy used to describe the interaction b...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.232925</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question  \\\n",
              "0  How does winning impact the retention of great...   \n",
              "1  How does the constant change in the world make...   \n",
              "2  What is the concept of \"Task Relevant Maturity...   \n",
              "3  Why is it important to focus on strength rathe...   \n",
              "4  What analogy is used to describe the interacti...   \n",
              "\n",
              "                                              answer  \\\n",
              "0  Winning is crucial for retaining great people ...   \n",
              "1  The constant change in the world makes it diff...   \n",
              "2  The concept of \"Task Relevant Maturity\" refers...   \n",
              "3  It is important to focus on strength rather th...   \n",
              "4  The analogy used to describe the interaction b...   \n",
              "\n",
              "                                            contexts  \\\n",
              "0  [The only way a company in that situation can ...   \n",
              "1  [tunity, someone else generally will and it wi...   \n",
              "2  [book High Output Management, where he describ...   \n",
              "3  [back ‚Äî perhaps abstractly ‚Äî about all of her ...   \n",
              "4  [investors, potential customers, potential par...   \n",
              "\n",
              "                                        ground_truth  faithfulness  \\\n",
              "0  Companies that are winning never have a retent...           1.0   \n",
              "1  The constant change in the world makes it diff...           1.0   \n",
              "2  The concept of 'Task Relevant Maturity' refers...           1.0   \n",
              "3  When managing executives, it is important to f...           1.0   \n",
              "4  The analogy used to describe the interaction b...           0.0   \n",
              "\n",
              "   answer_relevancy  context_recall  context_precision  answer_correctness  \n",
              "0          0.927039        0.000000           0.805556            0.688864  \n",
              "1          0.964069        1.000000           0.645833            0.333131  \n",
              "2          0.937940        1.000000           1.000000            0.847315  \n",
              "3          0.912358        0.333333           1.000000            0.616126  \n",
              "4          1.000000        0.000000           0.125000            0.232925  "
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "advanced_retrieval_results_df = advanced_retrieval_results.to_pandas()\n",
        "advanced_retrieval_results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0hzqq5VtZ2a"
      },
      "source": [
        "## Task 3: Evaluating our Adjusted Pipeline Against Our Baseline\n",
        "\n",
        "Now we can compare our results and see what directional changes occured!\n",
        "\n",
        "Let's refresh with our initial metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WWGRaF5qx3V",
        "outputId": "7924b9a5-1bfc-4d26-f1f7-75e10fb64857"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'faithfulness': 0.8500, 'answer_relevancy': 0.9336, 'context_recall': 0.6667, 'context_precision': 0.7556, 'answer_correctness': 0.5340}"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFv_yAeotmFs"
      },
      "source": [
        "And see how our advanced retrieval modified our chain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpV11dxJo7xa",
        "outputId": "2ce6e4b7-f037-4fd4-ca0c-1d47ff5dc522"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'faithfulness': 0.8000, 'answer_relevancy': 0.9483, 'context_recall': 0.4667, 'context_precision': 0.7153, 'answer_correctness': 0.5437}"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "advanced_retrieval_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "62NYn3iAvTjM",
        "outputId": "732eec56-d4ef-4403-cc90-62d0c81c37cf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Metric</th>\n",
              "      <th>Baseline</th>\n",
              "      <th>MultiQueryRetriever with Document Stuffing</th>\n",
              "      <th>Delta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>faithfulness</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>-0.050000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>answer_relevancy</td>\n",
              "      <td>0.933587</td>\n",
              "      <td>0.948281</td>\n",
              "      <td>0.014695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>context_recall</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>-0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>context_precision</td>\n",
              "      <td>0.755556</td>\n",
              "      <td>0.715278</td>\n",
              "      <td>-0.040278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>answer_correctness</td>\n",
              "      <td>0.533988</td>\n",
              "      <td>0.543672</td>\n",
              "      <td>0.009684</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Metric  Baseline  MultiQueryRetriever with Document Stuffing  \\\n",
              "0        faithfulness  0.850000                                    0.800000   \n",
              "1    answer_relevancy  0.933587                                    0.948281   \n",
              "2      context_recall  0.666667                                    0.466667   \n",
              "3   context_precision  0.755556                                    0.715278   \n",
              "4  answer_correctness  0.533988                                    0.543672   \n",
              "\n",
              "      Delta  \n",
              "0 -0.050000  \n",
              "1  0.014695  \n",
              "2 -0.200000  \n",
              "3 -0.040278  \n",
              "4  0.009684  "
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_original = pd.DataFrame(list(results.items()), columns=['Metric', 'Baseline'])\n",
        "df_comparison = pd.DataFrame(list(advanced_retrieval_results.items()), columns=['Metric', 'MultiQueryRetriever with Document Stuffing'])\n",
        "\n",
        "df_merged = pd.merge(df_original, df_comparison, on='Metric')\n",
        "\n",
        "df_merged['Delta'] = df_merged['MultiQueryRetriever with Document Stuffing'] - df_merged['Baseline']\n",
        "\n",
        "df_merged"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJKEOLNs5v0R"
      },
      "source": [
        "## Task 4: Testing OpenAI's Claim\n",
        "\n",
        "Now that we've seen how our retriever can impact the performance of our RAG pipeline - let's see how changing our embedding model impacts performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM4KRhJYEL-h"
      },
      "source": [
        "####üèóÔ∏è Activity #2:\n",
        "\n",
        "Please provide markdown, or code comments, to explain which each of the following steps are doing!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "Gv_tv4w86bPb"
      },
      "outputs": [],
      "source": [
        "# Create new OpenAI Embeddigs object with Text Embedding 3 (TE3) Small model for comparision\n",
        "new_embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "-JPe1_Jx6Rnw"
      },
      "outputs": [],
      "source": [
        "# Recreate vector store to store embedded vectors using the new TE3 Embedding model\n",
        "vector_store = Qdrant.from_documents(\n",
        "    documents,\n",
        "    new_embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"PMarca Blogs - TE3 - MQR\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "H-HuozNf6muZ"
      },
      "outputs": [],
      "source": [
        "# Cast vector store as retriever \n",
        "new_retriever = vector_store.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "M6Tyc3ZY7Km2"
      },
      "outputs": [],
      "source": [
        "# We are going to use MultiQueryRetriever with the new Embedding Model\n",
        "new_advanced_retriever = MultiQueryRetriever.from_llm(retriever=new_retriever, llm=primary_qa_llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "s5QSJIhm7SKr"
      },
      "outputs": [],
      "source": [
        "# Combine the advanced retriever with doc chain to create a new retrieval chain\n",
        "new_retrieval_chain = create_retrieval_chain(new_advanced_retriever, document_chain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "MBVjl1UK7fd7"
      },
      "outputs": [],
      "source": [
        "# Generate responses again through the new retrieval chain\n",
        "answers = []\n",
        "contexts = []\n",
        "\n",
        "# Prepare the necessary lists to align answer and context to input\n",
        "for question in test_questions:\n",
        "  response = new_retrieval_chain.invoke({\"input\" : question})\n",
        "  answers.append(response[\"answer\"])\n",
        "  contexts.append([context.page_content for context in response[\"context\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "lTBrs0zr7iyG"
      },
      "outputs": [],
      "source": [
        "# Prepare the dataset by bringing it all together\n",
        "new_response_dataset_advanced_retrieval = Dataset.from_dict({\n",
        "    \"question\" : test_questions[0:TRUNC_SIZE],\n",
        "    \"answer\" : answers[0:TRUNC_SIZE],\n",
        "    \"contexts\" : contexts[0:TRUNC_SIZE],\n",
        "    \"ground_truth\" : test_groundtruths[0:TRUNC_SIZE]\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "399f6ec046c34c26818a07c5efc6845a",
            "7f82e0a3c3684460b8dda773d283b535",
            "cfa01f60b62f4a88806d85cee5ac0fa6",
            "38988d3f6f5f4de3b3d4be7fec89c3c7",
            "87bd0ad74d4345dea4b409d64524f6e7",
            "8cb506949697432db061878397d196f1",
            "e7831a581d024e3ebb4026a89ceef127",
            "18701fc64eb44d26b8aa1ae0af64d09f",
            "a6581091161c489d877c2cfec432f6ae",
            "42dcc945d1624f69b63bed2fa52cc4fa",
            "5524289f1e594a5eac60ee29d9f4249c"
          ]
        },
        "id": "hG5h-D8n7sZp",
        "outputId": "6760b49b-4576-4bee-e61a-293df24e2bc3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:53<00:00,  2.27s/it]\n"
          ]
        }
      ],
      "source": [
        "# Finally start the evaluation for the new Embedding Model\n",
        "new_advanced_retrieval_results = evaluate(new_response_dataset_advanced_retrieval, metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uHdcpsZ76kj",
        "outputId": "53a4f4ef-13ce-4a89-a06e-6c255ed3c025"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'faithfulness': 0.8750, 'answer_relevancy': 0.9450, 'context_recall': 0.8000, 'context_precision': 0.5696, 'answer_correctness': 0.5133}"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Prit out the relevant results\n",
        "new_advanced_retrieval_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "s4TyaCUQ79Ke",
        "outputId": "c496266c-bf4a-4a3a-cd27-1d8abbf5bdb3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Metric</th>\n",
              "      <th>ADA + Baseline</th>\n",
              "      <th>ADA + MQR</th>\n",
              "      <th>TE3 + MQR</th>\n",
              "      <th>ADA + MQR -&gt; TE3 + MQR</th>\n",
              "      <th>Baseline -&gt; TE3 + MQR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>faithfulness</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.075000</td>\n",
              "      <td>0.025000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>answer_relevancy</td>\n",
              "      <td>0.933587</td>\n",
              "      <td>0.948281</td>\n",
              "      <td>0.944968</td>\n",
              "      <td>-0.003313</td>\n",
              "      <td>0.011382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>context_recall</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.133333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>context_precision</td>\n",
              "      <td>0.755556</td>\n",
              "      <td>0.715278</td>\n",
              "      <td>0.569571</td>\n",
              "      <td>-0.145706</td>\n",
              "      <td>-0.185984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>answer_correctness</td>\n",
              "      <td>0.533988</td>\n",
              "      <td>0.543672</td>\n",
              "      <td>0.513261</td>\n",
              "      <td>-0.030412</td>\n",
              "      <td>-0.020727</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Metric  ADA + Baseline  ADA + MQR  TE3 + MQR  \\\n",
              "0        faithfulness        0.850000   0.800000   0.875000   \n",
              "1    answer_relevancy        0.933587   0.948281   0.944968   \n",
              "2      context_recall        0.666667   0.466667   0.800000   \n",
              "3   context_precision        0.755556   0.715278   0.569571   \n",
              "4  answer_correctness        0.533988   0.543672   0.513261   \n",
              "\n",
              "   ADA + MQR -> TE3 + MQR  Baseline -> TE3 + MQR  \n",
              "0                0.075000               0.025000  \n",
              "1               -0.003313               0.011382  \n",
              "2                0.333333               0.133333  \n",
              "3               -0.145706              -0.185984  \n",
              "4               -0.030412              -0.020727  "
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Combine baseline with previous and new results for each comparison\n",
        "df_baseline = pd.DataFrame(list(results.items()), columns=['Metric', 'ADA + Baseline'])\n",
        "df_original = pd.DataFrame(list(advanced_retrieval_results.items()), columns=['Metric', 'ADA + MQR'])\n",
        "df_comparison = pd.DataFrame(list(new_advanced_retrieval_results.items()), columns=['Metric', 'TE3 + MQR'])\n",
        "\n",
        "df_merged = pd.merge(df_original, df_comparison, on='Metric')\n",
        "df_merged = pd.merge(df_baseline, df_merged, on=\"Metric\")\n",
        "\n",
        "df_merged['ADA + MQR -> TE3 + MQR'] = df_merged['TE3 + MQR'] - df_merged['ADA + MQR']\n",
        "df_merged['Baseline -> TE3 + MQR'] = df_merged['TE3 + MQR'] - df_merged['ADA + Baseline']\n",
        "\n",
        "df_merged"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRmkcMrxC4Me"
      },
      "source": [
        "####‚ùì Question #4:\n",
        "\n",
        "Do you think, in your opinion, `text-embedding-3-small` is significantly better than `ada`?\n",
        "\n",
        "> **Answer:** Based on the limited dataset over which we could run the evaluation due to rate limiting by OpenAI APIs, `TE3` seems marginally better than `ADA`. The main gain it has is on `context_recall`. As goes retrieval, so goes generation. So, this improved retrieval has a positive impact. Though, `context_precision` suffers which could lead to low quality answers. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOciJLABDBnA"
      },
      "source": [
        "## BONUS ACTIVITY: Using a Better Generator\n",
        "\n",
        "Now that we've seen how much more effective a better Retrieval pipeline is, let's look at what impact a better(?) Generator is!\n",
        "\n",
        "Adapt the above `TE3 + MQR` pipeline to use `GPT-4o` and compare the results below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MY8l2EksDH43"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "05390d20f1b445b5b02529ee7a99f6d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_589c2004f5504a239615dec8671785d0",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_25d3337c457f4c748ed8bf78f5a27fe8",
            "value": 100
          }
        },
        "05ab48866b5d49df9567ce9cbda5ee2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_49c1ef316e404052a7c8528781db3f9a",
              "IPY_MODEL_2dcb3e2fdf164e35a27a79cfae65933a",
              "IPY_MODEL_202f4244384a4501bfc1ffa50af96a1f"
            ],
            "layout": "IPY_MODEL_d93698b0506743ff98fdb998cfb7080a"
          }
        },
        "1317f4e20e1c4574a360345b427c3e8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92ef10fab64c4f40a93da3d31b572016",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3b43c3f561e34d019007ac9a0125b28d",
            "value": "‚Äá1248/1248‚Äá[00:46&lt;00:00,‚Äá13.97it/s]"
          }
        },
        "18701fc64eb44d26b8aa1ae0af64d09f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19acd28bfa2e4a7a83bc42faea5de770": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d43002974f24e8a8b6961cddc04ce47": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fb5a4b71deb406fa2f342c88b9e4e1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e1d22c19aff4c768d643c249e425d00",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3a498872a68049329b4d206629b9b3bf",
            "value": "embedding‚Äánodes:‚Äá100%"
          }
        },
        "202f4244384a4501bfc1ffa50af96a1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a10a7577a99b4683a1d59a09d88f93a1",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_444bc7dae1aa4e098b79655428599310",
            "value": "‚Äá20/20‚Äá[01:04&lt;00:00,‚Äá10.00s/it]"
          }
        },
        "25d3337c457f4c748ed8bf78f5a27fe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2aa53858803d4ad39113009d86dd67fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "2dcb3e2fdf164e35a27a79cfae65933a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60a663f8736a43bcb47ac6c5f37ec597",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e6edc46811064de2b74a6a477c4a44b7",
            "value": 20
          }
        },
        "31064d2adec14238a609d3f9791c64f3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32514310070a426ea247c9f1bc66b630": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e7520df71de40e0af5589b6aeb95171",
              "IPY_MODEL_05390d20f1b445b5b02529ee7a99f6d6",
              "IPY_MODEL_3380693903474d2585638f7e3458fcd6"
            ],
            "layout": "IPY_MODEL_1d43002974f24e8a8b6961cddc04ce47"
          }
        },
        "3380693903474d2585638f7e3458fcd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31064d2adec14238a609d3f9791c64f3",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4f482b8ce7a54c1787394fb7d90391a0",
            "value": "‚Äá100/100‚Äá[00:33&lt;00:00,‚Äá‚Äá1.55s/it]"
          }
        },
        "356b929fa8dc42538767c58dcce12217": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37ec9b5c847749439d7c155ac3b1ec68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89a7c333d0b241169dc29ed998b2c9c4",
            "max": 1248,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88c8557741734e59a6099bb5fa260f6e",
            "value": 1248
          }
        },
        "38988d3f6f5f4de3b3d4be7fec89c3c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42dcc945d1624f69b63bed2fa52cc4fa",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5524289f1e594a5eac60ee29d9f4249c",
            "value": "‚Äá100/100‚Äá[00:45&lt;00:00,‚Äá‚Äá1.68s/it]"
          }
        },
        "399f6ec046c34c26818a07c5efc6845a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f82e0a3c3684460b8dda773d283b535",
              "IPY_MODEL_cfa01f60b62f4a88806d85cee5ac0fa6",
              "IPY_MODEL_38988d3f6f5f4de3b3d4be7fec89c3c7"
            ],
            "layout": "IPY_MODEL_87bd0ad74d4345dea4b409d64524f6e7"
          }
        },
        "3a498872a68049329b4d206629b9b3bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b43c3f561e34d019007ac9a0125b28d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e7520df71de40e0af5589b6aeb95171": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97abe811c89c44dcacd7e39074d22546",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_87a3d4b2ed5f4f1ca895c6a1981eb847",
            "value": "Evaluating:‚Äá100%"
          }
        },
        "40343486e3ea4e5fae55b5a528f139d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "42dcc945d1624f69b63bed2fa52cc4fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "444bc7dae1aa4e098b79655428599310": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49c1ef316e404052a7c8528781db3f9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19acd28bfa2e4a7a83bc42faea5de770",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_356b929fa8dc42538767c58dcce12217",
            "value": "Generating:‚Äá100%"
          }
        },
        "4cefefc6cf714a68924e1b8d5e59aba9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c2b92989d7448e9bf65306c4f2f7d93",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a34b3906cd514234a115c7bf6757ca9d",
            "value": "Evaluating:‚Äá100%"
          }
        },
        "4f482b8ce7a54c1787394fb7d90391a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5524289f1e594a5eac60ee29d9f4249c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "589c2004f5504a239615dec8671785d0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c2b92989d7448e9bf65306c4f2f7d93": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60a663f8736a43bcb47ac6c5f37ec597": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e1d22c19aff4c768d643c249e425d00": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f82e0a3c3684460b8dda773d283b535": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cb506949697432db061878397d196f1",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e7831a581d024e3ebb4026a89ceef127",
            "value": "Evaluating:‚Äá100%"
          }
        },
        "831b4dab6ff94d239d2824d390e01308": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4cefefc6cf714a68924e1b8d5e59aba9",
              "IPY_MODEL_fd7f5542a22d44388dda12ca19443a1f",
              "IPY_MODEL_93bf9b194c04460abffa192c19bcf67b"
            ],
            "layout": "IPY_MODEL_83985f58744a46cfbd001ce5957f3e4a"
          }
        },
        "83985f58744a46cfbd001ce5957f3e4a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87a3d4b2ed5f4f1ca895c6a1981eb847": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87bd0ad74d4345dea4b409d64524f6e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88c8557741734e59a6099bb5fa260f6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89a7c333d0b241169dc29ed998b2c9c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cb506949697432db061878397d196f1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92ef10fab64c4f40a93da3d31b572016": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93bf9b194c04460abffa192c19bcf67b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cee2268aa21643e6ad77117c67ec1600",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c79f28da88f44d69aa87905c089df333",
            "value": "‚Äá100/100‚Äá[00:44&lt;00:00,‚Äá‚Äá1.69s/it]"
          }
        },
        "97abe811c89c44dcacd7e39074d22546": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a03fefb9fa5a40ff947dc4ccd3c80318": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a10a7577a99b4683a1d59a09d88f93a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a34b3906cd514234a115c7bf6757ca9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6581091161c489d877c2cfec432f6ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c79f28da88f44d69aa87905c089df333": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cee2268aa21643e6ad77117c67ec1600": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfa01f60b62f4a88806d85cee5ac0fa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18701fc64eb44d26b8aa1ae0af64d09f",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6581091161c489d877c2cfec432f6ae",
            "value": 100
          }
        },
        "d93698b0506743ff98fdb998cfb7080a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6edc46811064de2b74a6a477c4a44b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e7831a581d024e3ebb4026a89ceef127": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f75fdd56268a4b83a7fb7e4a3b2cce82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1fb5a4b71deb406fa2f342c88b9e4e1d",
              "IPY_MODEL_37ec9b5c847749439d7c155ac3b1ec68",
              "IPY_MODEL_1317f4e20e1c4574a360345b427c3e8a"
            ],
            "layout": "IPY_MODEL_2aa53858803d4ad39113009d86dd67fc"
          }
        },
        "fd7f5542a22d44388dda12ca19443a1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a03fefb9fa5a40ff947dc4ccd3c80318",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_40343486e3ea4e5fae55b5a528f139d8",
            "value": 100
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
